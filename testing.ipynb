{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants for grid elements\n",
    "EMPTY = 0\n",
    "WALL = 1\n",
    "CAPTURE_NEUTRAL = 2\n",
    "CAPTURE_P1 = 3\n",
    "CAPTURE_P2 = 4\n",
    "PLAYER1 = 5\n",
    "PLAYER2 = 6\n",
    "\n",
    "# Define action constants\n",
    "MOVE_N0 = -1\n",
    "MOVE_UP = 0\n",
    "MOVE_DOWN = 1\n",
    "MOVE_LEFT = 2\n",
    "MOVE_RIGHT = 3\n",
    "ATTACK = 4\n",
    "DEFEND = 6\n",
    "\n",
    "# Game settings\n",
    "GRID_SIZE = 10\n",
    "MAX_TURNS = 30\n",
    "INITIAL_HEALTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset(self):\n",
    "        # Create an empty grid and add random walls and capture points\n",
    "        self.grid = np.full((self.grid_size, self.grid_size), EMPTY)\n",
    "        self._place_walls()\n",
    "        self._place_capture_points()\n",
    "\n",
    "        # Place players in random empty positions\n",
    "        self.player1 = {\"position\": self._get_random_empty_cell(), \"health\": INITIAL_HEALTH}\n",
    "        self.player2 = {\"position\": self._get_random_empty_cell(), \"health\": INITIAL_HEALTH}\n",
    "\n",
    "        # Mark players on the grid\n",
    "        self._update_grid_positions()\n",
    "        self.turn = 0\n",
    "        return self._get_observation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _place_walls(self):\n",
    "    # Randomly place a few walls\n",
    "    num_walls = int(self.grid_size * self.grid_size * 0.1)  # 10% cells are walls\n",
    "    for _ in range(num_walls):\n",
    "        x, y = random.randint(0, self.grid_size-1), random.randint(0, self.grid_size-1)\n",
    "        self.grid[x, y] = WALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _place_capture_points(self):\n",
    "    # Randomly place some capture points (neutral)\n",
    "    num_points = int(self.grid_size * self.grid_size * 0.05)  # 5% cells are capture points\n",
    "    for _ in range(num_points):\n",
    "        x, y = random.randint(0, self.grid_size-1), random.randint(0, self.grid_size-1)\n",
    "        # Place a capture point only on an empty cell\n",
    "        if self.grid[x, y] == EMPTY:\n",
    "            self.grid[x, y] = CAPTURE_NEUTRAL\n",
    "            \n",
    "def _get_random_empty_cell(self):\n",
    "        while True:\n",
    "            x, y = random.randint(0, self.grid_size-1), random.randint(0, self.grid_size-1)\n",
    "            if self.grid[x, y] == EMPTY:\n",
    "                return (x, y)\n",
    "\n",
    "def _update_grid_positions(self):\n",
    "    # Clear previous player positions (set to empty or preserve capture points)\n",
    "    for i in range(self.grid_size):\n",
    "        for j in range(self.grid_size):\n",
    "            if self.grid[i, j] in [PLAYER1, PLAYER2]:\n",
    "                self.grid[i, j] = EMPTY\n",
    "            if self.grid[i, j] in [CAPTURE_P1, CAPTURE_P2]:\n",
    "                self.grid[i, j] = CAPTURE_NEUTRAL\n",
    "            # Do not override walls or capture points\n",
    "\n",
    "    # Mark new positions\n",
    "    p1_x, p1_y = self.player1[\"position\"]\n",
    "    p2_x, p2_y = self.player2[\"position\"]\n",
    "    self.grid[p1_x, p1_y] = PLAYER1\n",
    "    self.grid[p2_x, p2_y] = PLAYER2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_observation(self):\n",
    "        # Construct a dictionary observation\n",
    "        obs = {\n",
    "            \"grid\": self.grid.copy(),\n",
    "            \"player\": {\n",
    "                \"position\": self.player1[\"position\"],\n",
    "                \"health\": self.player1[\"health\"],\n",
    "            },\n",
    "            \"opponent\": {\n",
    "                \"position\": self.player2[\"position\"],\n",
    "                \"health\": self.player2[\"health\"]\n",
    "            },\n",
    "            \"turn\": self.turn\n",
    "        }\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(self, actions):\n",
    "    \"\"\"\n",
    "    Expects a tuple of actions (action_p1, action_p2)\n",
    "    Both players act simultaneously.\n",
    "    Returns:\n",
    "        observation, rewards, done, info\n",
    "    \"\"\"\n",
    "    action_p1, action_p2 = actions\n",
    "    rewards = [0, 0]\n",
    "\n",
    "    # Process player 1 action\n",
    "    rewards[0] += self._process_action(self.player1, self.player2, action_p1, is_player1=True)\n",
    "    # Process player 2 action\n",
    "    rewards[1] += self._process_action(self.player2, self.player1, action_p2, is_player1=False)\n",
    "\n",
    "    # Update grid positions after actions\n",
    "    self._update_grid_positions()\n",
    "    self.turn += 1\n",
    "\n",
    "    # Check if game is over\n",
    "    done = self.turn >= self.max_turns or self.player1[\"health\"] <= 0 or self.player2[\"health\"] <= 0\n",
    "    info = {}\n",
    "    return self._get_observation(), rewards, done, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_action(self, player, opponent, action, is_player1=True):\n",
    "        reward = 0\n",
    "        # Get current position\n",
    "        x, y = player[\"position\"]\n",
    "\n",
    "        # Movement: compute new position\n",
    "        if action in [MOVE_N0,MOVE_UP, MOVE_DOWN, MOVE_LEFT, MOVE_RIGHT]:\n",
    "            new_x, new_y = x, y\n",
    "            if action == MOVE_UP:\n",
    "                new_x -= 1\n",
    "            elif action == MOVE_DOWN:\n",
    "                new_x += 1\n",
    "            elif action == MOVE_LEFT:\n",
    "                new_y -= 1\n",
    "            elif action == MOVE_RIGHT:\n",
    "                new_y += 1\n",
    "\n",
    "            # Check boundaries and obstacles\n",
    "            if 0 <= new_x < self.grid_size and 0 <= new_y < self.grid_size:\n",
    "                if self.grid[new_x, new_y] not in [WALL, PLAYER1, PLAYER2]:\n",
    "                    player[\"position\"] = (new_x, new_y)\n",
    "                    if(self.grid[new_x,new_y]==CAPTURE_NEUTRAL):\n",
    "                        self.grid[new_x, new_y] = CAPTURE_P1 if is_player1 else CAPTURE_P2\n",
    "                else:\n",
    "                    reward -= 1  # penalty for invalid move\n",
    "                if self.grid[new_x, new_y] == CAPTURE_NEUTRAL:\n",
    "                    reward += 5\n",
    "            else:\n",
    "                reward -= 1  # penalty for moving out of bounds\n",
    "\n",
    "        elif action == ATTACK:\n",
    "            # Check if opponent is adjacent (Manhattan distance = 1)\n",
    "            opp_x, opp_y = opponent[\"position\"]\n",
    "            if abs(opp_x - x) + abs(opp_y - y) == 1:\n",
    "                damage = 10\n",
    "                # If opponent defended in their turn, damage reduction could be applied\n",
    "                opponent[\"health\"] -= damage\n",
    "                reward += 10  # reward for dealing damage\n",
    "                # Bonus for defeating the opponent will be applied in step()\n",
    "            else:\n",
    "                reward -= 2  # invalid attack\n",
    "\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(self):\n",
    "    # Simple text-based rendering of the grid\n",
    "    symbol_map = {\n",
    "        EMPTY: \".\",\n",
    "        WALL: \"#\",\n",
    "        CAPTURE_NEUTRAL: \"C\",\n",
    "        CAPTURE_P1: \"1\",\n",
    "        CAPTURE_P2: \"2\",\n",
    "        PLAYER1: \"A\",  # Agent A\n",
    "        PLAYER2: \"B\"   # Agent B\n",
    "    }\n",
    "    render_grid = \"\"\n",
    "    for i in range(self.grid_size):\n",
    "        for j in range(self.grid_size):\n",
    "            render_grid += symbol_map.get(self.grid[i, j], \"?\") + \" \"\n",
    "        render_grid += \"\\n\"\n",
    "    print(render_grid)\n",
    "    print(f\"Turn: {self.turn}\")\n",
    "    print(f\"Player A (Health: {self.player1['health']})\")\n",
    "    print(f\"Player B (Health: {self.player2['health']})\\n\")\n",
    "    return render_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants for grid elements\n",
    "EMPTY = 0\n",
    "WALL = 1\n",
    "CAPTURE_NEUTRAL = 2\n",
    "CAPTURE_P1 = 3\n",
    "CAPTURE_P2 = 4\n",
    "PLAYER1 = 5\n",
    "PLAYER2 = 6\n",
    "# Define action constants\n",
    "MOVE_NO = -1\n",
    "MOVE_UP = 0\n",
    "MOVE_DOWN = 1\n",
    "MOVE_LEFT = 2\n",
    "MOVE_RIGHT = 3\n",
    "ATTACK = 4\n",
    "DEFEND = 6\n",
    "# Game settings\n",
    "GRID_SIZE = 10\n",
    "MAX_TURNS = 30\n",
    "INITIAL_HEALTH = 100\n",
    "\n",
    "class CombatArenaEnv:\n",
    "    def __init__(self, grid_size=GRID_SIZE, max_turns=MAX_TURNS):\n",
    "        self.grid_size = grid_size\n",
    "        self.max_turns = max_turns\n",
    "        self.turn = 0\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        # Create an empty grid and add random walls and capture points\n",
    "        self.grid = np.full((self.grid_size, self.grid_size), EMPTY)\n",
    "        self._place_walls()\n",
    "        self._place_capture_points()\n",
    "\n",
    "        # Place players in random empty positions\n",
    "        self.player1 = {\"position\": self._get_random_empty_cell(), \"health\": INITIAL_HEALTH, \"capture_points\": 0}\n",
    "        self.player2 = {\"position\": self._get_random_empty_cell(), \"health\": INITIAL_HEALTH, \"capture_points\": 0}\n",
    "\n",
    "        # Mark players on the grid\n",
    "        self._update_grid_positions()\n",
    "        self.turn = 0\n",
    "        self.render_graphic()\n",
    "        return self.get_observation_for_agent(True), self.get_observation_for_agent(False)\n",
    "\n",
    "    def _place_walls(self):\n",
    "    # Randomly place a few walls\n",
    "        num_walls = int(self.grid_size * self.grid_size * 0.1)  # 10% cells are walls\n",
    "        for _ in range(num_walls):\n",
    "            x, y = random.randint(0, self.grid_size-1), random.randint(0, self.grid_size-1)\n",
    "            self.grid[x, y] = WALL\n",
    "    \n",
    "    def _place_capture_points(self):\n",
    "        # Randomly place some capture points (neutral)\n",
    "        num_points = int(self.grid_size * self.grid_size * 0.05)  # 5% cells are capture points\n",
    "        for _ in range(num_points):\n",
    "            x, y = random.randint(0, self.grid_size-1), random.randint(0, self.grid_size-1)\n",
    "            # Place a capture point only on an empty cell\n",
    "            if self.grid[x, y] == EMPTY:\n",
    "                self.grid[x, y] = CAPTURE_NEUTRAL\n",
    "            \n",
    "    def _get_random_empty_cell(self):\n",
    "            while True:\n",
    "                x, y = random.randint(0, self.grid_size-1), random.randint(0, self.grid_size-1)\n",
    "                if self.grid[x, y] == EMPTY:\n",
    "                    return (x, y)\n",
    "\n",
    "    def _update_grid_positions(self):\n",
    "        # Clear previous player positions (set to empty or preserve capture points)\n",
    "        for i in range(self.grid_size):\n",
    "            for j in range(self.grid_size):\n",
    "                if self.grid[i, j] in [CAPTURE_P1, CAPTURE_P2]:\n",
    "                    self.grid[i, j] = CAPTURE_NEUTRAL\n",
    "                elif self.grid[i, j] in [PLAYER1, PLAYER2]:\n",
    "                    self.grid[i, j] = EMPTY\n",
    "\n",
    "        p1_x, p1_y = self.player1[\"position\"]\n",
    "        p2_x, p2_y = self.player2[\"position\"]\n",
    "        self.grid[p1_x, p1_y] = PLAYER1\n",
    "        self.grid[p2_x, p2_y] = PLAYER2\n",
    "    \n",
    "    def get_observation_for_agent(self, is_agent_one=True):\n",
    "        if is_agent_one:\n",
    "            player = self.player1\n",
    "            opponent = self.player2\n",
    "        else:\n",
    "            player = self.player2\n",
    "            opponent = self.player1\n",
    "            \n",
    "        return {\n",
    "            \"grid\": self.grid.copy(),\n",
    "            \"player\": {\n",
    "                \"position\": player[\"position\"],\n",
    "                \"health\": player[\"health\"],\n",
    "                \"capture_points\": player[\"capture_points\"]\n",
    "            },\n",
    "            \"opponent\": {\n",
    "                \"position\": opponent[\"position\"],\n",
    "                \"health\": opponent[\"health\"]\n",
    "            },\n",
    "            \"turn\": self.turn\n",
    "        }\n",
    "    \n",
    "    def step(self, actions):\n",
    "        \"\"\"\n",
    "        Expects a tuple of actions (action_p1, action_p2)\n",
    "        Both players act simultaneously.\n",
    "        Returns:\n",
    "            observation, rewards, done, info\n",
    "        \"\"\"\n",
    "        action_p1, action_p2 = actions\n",
    "        rewards = [0, 0]\n",
    "\n",
    "        # Process player 1 action\n",
    "        rewards[0] += self._process_action(self.player1, self.player2, action_p1, is_player1=True)\n",
    "        # Process player 2 action\n",
    "        rewards[1] += self._process_action(self.player2, self.player1, action_p2, is_player1=False)\n",
    "\n",
    "        # Update grid positions after actions\n",
    "        self._update_grid_positions()\n",
    "        self.turn += 1\n",
    "\n",
    "        # Check if game is over\n",
    "        done = self.turn >= self.max_turns or self.player1[\"health\"] <= 0 or self.player2[\"health\"] <= 0\n",
    "        info = {}\n",
    "        return self.get_observation_for_agent(True),self.get_observation_for_agent(False), rewards, done, info\n",
    "    \n",
    "    def _process_action(self, player, opponent, action, is_player1=True):\n",
    "        reward = 0\n",
    "        # Get current position\n",
    "        x, y = player[\"position\"]\n",
    "\n",
    "        # Movement: compute new position\n",
    "        if action in [MOVE_NO,MOVE_UP, MOVE_DOWN, MOVE_LEFT, MOVE_RIGHT]:\n",
    "            new_x, new_y = x, y\n",
    "            if action == MOVE_UP:\n",
    "                new_x -= 1\n",
    "            elif action == MOVE_DOWN:\n",
    "                new_x += 1\n",
    "            elif action == MOVE_LEFT:\n",
    "                new_y -= 1\n",
    "            elif action == MOVE_RIGHT:\n",
    "                new_y += 1\n",
    "\n",
    "            # Check boundaries and obstacles\n",
    "            if 0 <= new_x < self.grid_size and 0 <= new_y < self.grid_size:\n",
    "                if self.grid[new_x, new_y] not in [WALL, PLAYER1, PLAYER2]:\n",
    "                    player[\"position\"] = (new_x, new_y)\n",
    "                    if(self.grid[new_x,new_y]==CAPTURE_NEUTRAL):\n",
    "                        self.grid[new_x, new_y] = CAPTURE_P1 if is_player1 else CAPTURE_P2\n",
    "                        reward += 5\n",
    "                        player[\"capture_points\"] += 1\n",
    "                else:\n",
    "                    reward -= 1  # penalty for invalid move\n",
    "            else:\n",
    "                reward -= 1  # penalty for moving out of bounds\n",
    "\n",
    "        elif action == ATTACK:\n",
    "            # Check if opponent is adjacent (Manhattan distance = 1)\n",
    "            opp_x, opp_y = opponent[\"position\"]\n",
    "            if abs(opp_x - x) + abs(opp_y - y) == 1:\n",
    "                damage = 10\n",
    "                # If opponent defended in their turn, damage reduction could be applied\n",
    "                opponent[\"health\"] -= damage\n",
    "                reward += 10  # reward for dealing damage\n",
    "                # Bonus for defeating the opponent will be applied in step()\n",
    "            else:\n",
    "                reward -= 2  # invalid attack\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def render_graphic(self, ax=None, fig=None):\n",
    "        # Define colors for each grid element\n",
    "        color_map = {\n",
    "            EMPTY: \"white\",\n",
    "            WALL: \"black\",\n",
    "            CAPTURE_NEUTRAL: \"yellow\",\n",
    "            CAPTURE_P1: \"blue\",\n",
    "            CAPTURE_P2: \"red\",\n",
    "            PLAYER1: \"green\",\n",
    "            PLAYER2: \"orange\"\n",
    "        }\n",
    "\n",
    "        # If no axis is provided, create new figure\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "        # Create a color grid\n",
    "        color_grid = np.empty((self.grid_size, self.grid_size), dtype=object)\n",
    "        for i in range(self.grid_size):\n",
    "            for j in range(self.grid_size):\n",
    "                color_grid[i, j] = color_map.get(self.grid[i, j], \"gray\")\n",
    "\n",
    "        # Plot the grid\n",
    "        for i in range(self.grid_size):\n",
    "            for j in range(self.grid_size):\n",
    "                rect = plt.Rectangle((j, self.grid_size - i - 1), 1, 1, \n",
    "                                facecolor=color_grid[i, j], edgecolor=\"black\")\n",
    "                ax.add_patch(rect)\n",
    "\n",
    "        # Set axis limits and labels\n",
    "        ax.set_xlim(0, self.grid_size)\n",
    "        ax.set_ylim(0, self.grid_size)\n",
    "        ax.set_xticks(range(self.grid_size))\n",
    "        ax.set_yticks(range(self.grid_size))\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect(\"equal\")\n",
    "        \n",
    "        # Update title\n",
    "        ax.set_title(f\"Turn: {self.turn}\\nPlayer A (Health: {self.player1['health']}) Capture Points: {self.player1['capture_points']} | \" \n",
    "                    f\"Player B (Health: {self.player2['health']}) Player B Capture Points: {self.player2['capture_points']}\")\n",
    "        \n",
    "        # Only draw if in interactive mode\n",
    "        if plt.isinteractive():\n",
    "            fig.canvas.draw()\n",
    "            fig.canvas.flush_events()\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=CombatArenaEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions=(MOVE_UP, ATTACK)\n",
    "obs1, obs2, rewards, done, info = env.step(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAgent:\n",
    "    \"\"\"\n",
    "    Competitors should implement their own agent by subclassing BaseAgent.\n",
    "    The `select_action` method should return one of the 7 actions.\n",
    "    \"\"\"\n",
    "    def __init__(self, name=\"Agent\"):\n",
    "        self.name = name\n",
    "\n",
    "    def select_action(self, observation):\n",
    "        \"\"\"\n",
    "        Given an observation, return an action from the discrete action set.\n",
    "        Must be implemented by the competitor.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"select_action must be implemented by the agent subclass.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TacticalAgent(BaseAgent):\n",
    "    def __init__(self, name=\"TacticalAgent\"):\n",
    "        super().__init__(name)\n",
    "        self.previous_position = None\n",
    "        \n",
    "    def select_action(self, observation):\n",
    "        \"\"\"\n",
    "        Makes tactical decisions based on the current observation.\n",
    "        \n",
    "        Strategy:\n",
    "        1. If adjacent to enemy and health > 30, attack\n",
    "        2. If health is low (< 30), move away from enemy\n",
    "        3. Move towards nearest capture point if no immediate threats\n",
    "        4. If no better options, move randomly to valid position\n",
    "        \"\"\"\n",
    "        grid = observation[\"grid\"]\n",
    "        my_pos = observation[\"player\"][\"position\"]\n",
    "        enemy_pos = observation[\"opponent\"][\"position\"]\n",
    "        my_health = observation[\"player\"][\"health\"]\n",
    "        \n",
    "        # Calculate Manhattan distance to enemy\n",
    "        distance_to_enemy = abs(my_pos[0] - enemy_pos[0]) + abs(my_pos[1] - enemy_pos[1])\n",
    "        \n",
    "        # If adjacent to enemy and healthy, attack\n",
    "        if distance_to_enemy == 1 and my_health > 30:\n",
    "            return ATTACK\n",
    "            \n",
    "        # If low health, try to move away from enemy\n",
    "        if my_health < 30:\n",
    "            return self._move_away_from_enemy(grid, my_pos, enemy_pos)\n",
    "            \n",
    "        # Find nearest capture point and move towards it\n",
    "        nearest_capture = self._find_nearest_capture_point(grid, my_pos)\n",
    "        if nearest_capture:\n",
    "            return self._move_towards_target(grid, my_pos, nearest_capture)\n",
    "            \n",
    "        # If no better options, move randomly to valid position\n",
    "        return self._get_random_valid_move(grid, my_pos)\n",
    "    \n",
    "    def _move_away_from_enemy(self, grid, my_pos, enemy_pos):\n",
    "        \"\"\"Returns movement action that increases distance from enemy\"\"\"\n",
    "        best_distance = 0\n",
    "        best_action = MOVE_NO\n",
    "        \n",
    "        for action in [MOVE_UP, MOVE_DOWN, MOVE_LEFT, MOVE_RIGHT]:\n",
    "            new_pos = self._get_new_position(my_pos, action)\n",
    "            if self._is_valid_move(grid, new_pos):\n",
    "                distance = abs(new_pos[0] - enemy_pos[0]) + abs(new_pos[1] - enemy_pos[1])\n",
    "                if distance > best_distance:\n",
    "                    best_distance = distance\n",
    "                    best_action = action\n",
    "        \n",
    "        return best_action\n",
    "    \n",
    "    def _find_nearest_capture_point(self, grid, pos):\n",
    "        \"\"\"Returns coordinates of nearest neutral capture point\"\"\"\n",
    "        nearest_dist = float('inf')\n",
    "        nearest_point = None\n",
    "        \n",
    "        for i in range(len(grid)):\n",
    "            for j in range(len(grid[0])):\n",
    "                if grid[i, j] == CAPTURE_NEUTRAL:\n",
    "                    dist = abs(pos[0] - i) + abs(pos[1] - j)\n",
    "                    if dist < nearest_dist:\n",
    "                        nearest_dist = dist\n",
    "                        nearest_point = (i, j)\n",
    "        \n",
    "        return nearest_point\n",
    "    \n",
    "    def _move_towards_target(self, grid, current_pos, target_pos):\n",
    "        \"\"\"Returns movement action that reduces distance to target\"\"\"\n",
    "        dx = target_pos[0] - current_pos[0]\n",
    "        dy = target_pos[1] - current_pos[1]\n",
    "        \n",
    "        # Try vertical movement first\n",
    "        if dx > 0 and self._is_valid_move(grid, (current_pos[0] + 1, current_pos[1])):\n",
    "            return MOVE_DOWN\n",
    "        elif dx < 0 and self._is_valid_move(grid, (current_pos[0] - 1, current_pos[1])):\n",
    "            return MOVE_UP\n",
    "            \n",
    "        # Try horizontal movement\n",
    "        if dy > 0 and self._is_valid_move(grid, (current_pos[0], current_pos[1] + 1)):\n",
    "            return MOVE_RIGHT\n",
    "        elif dy < 0 and self._is_valid_move(grid, (current_pos[0], current_pos[1] - 1)):\n",
    "            return MOVE_LEFT\n",
    "            \n",
    "        return MOVE_NO\n",
    "    \n",
    "    def _get_new_position(self, pos, action):\n",
    "        \"\"\"Returns new position after applying action\"\"\"\n",
    "        if action == MOVE_UP:\n",
    "            return (pos[0] - 1, pos[1])\n",
    "        elif action == MOVE_DOWN:\n",
    "            return (pos[0] + 1, pos[1])\n",
    "        elif action == MOVE_LEFT:\n",
    "            return (pos[0], pos[1] - 1)\n",
    "        elif action == MOVE_RIGHT:\n",
    "            return (pos[0], pos[1] + 1)\n",
    "        return pos\n",
    "    \n",
    "    def _is_valid_move(self, grid, pos):\n",
    "        \"\"\"Checks if move is valid (within bounds and not into wall)\"\"\"\n",
    "        if not (0 <= pos[0] < len(grid) and 0 <= pos[1] < len(grid[0])):\n",
    "            return False\n",
    "        return grid[pos[0], pos[1]] != WALL\n",
    "    \n",
    "    def _get_random_valid_move(self, grid, pos):\n",
    "        \"\"\"Returns random valid movement action\"\"\"\n",
    "        valid_actions = [MOVE_NO]\n",
    "        for action in [MOVE_UP, MOVE_DOWN, MOVE_LEFT, MOVE_RIGHT]:\n",
    "            new_pos = self._get_new_position(pos, action)\n",
    "            if self._is_valid_move(grid, new_pos):\n",
    "                valid_actions.append(action)\n",
    "        return random.choice(valid_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg-python in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: future in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ffmpeg-python) (0.18.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "\n",
    "class GameVisualizer:\n",
    "    def __init__(self, env, figsize=(8, 8)):\n",
    "        self.env = env\n",
    "        self.frames = []  \n",
    "        self.figsize = figsize\n",
    "        \n",
    "        self.color_map = {\n",
    "            EMPTY: \"white\",\n",
    "            WALL: \"black\",\n",
    "            CAPTURE_NEUTRAL: \"yellow\",\n",
    "            CAPTURE_P1: \"blue\",\n",
    "            CAPTURE_P2: \"red\",\n",
    "            PLAYER1: \"green\",\n",
    "            PLAYER2: \"orange\"\n",
    "        }\n",
    "    \n",
    "    def capture_frame(self):\n",
    "        \"\"\"Capture current game state as frame data\"\"\"\n",
    "        frame_data = {\n",
    "            'grid': self.env.grid.copy(),\n",
    "            'turn': self.env.turn,\n",
    "            'p1_health': self.env.player1['health'],\n",
    "            'p2_health': self.env.player2['health'],\n",
    "            'p1_points': self.env.player1['capture_points'],\n",
    "            'p2_points': self.env.player2['capture_points']\n",
    "        }\n",
    "        self.frames.append(frame_data)\n",
    "    \n",
    "    def _create_frame(self, frame_data, ax):\n",
    "        \"\"\"Create visualization for a single frame\"\"\"\n",
    "        ax.clear()\n",
    "        \n",
    "        for i in range(self.env.grid_size):\n",
    "            for j in range(self.env.grid_size):\n",
    "                color = self.color_map.get(frame_data['grid'][i, j], \"gray\")\n",
    "                rect = Rectangle((j, self.env.grid_size - i - 1), \n",
    "                               1, 1, \n",
    "                               facecolor=color,\n",
    "                               edgecolor=\"black\")\n",
    "                ax.add_patch(rect)\n",
    "\n",
    "        ax.set_xlim(0, self.env.grid_size)\n",
    "        ax.set_ylim(0, self.env.grid_size)\n",
    "        ax.set_xticks(range(self.env.grid_size))\n",
    "        ax.set_yticks(range(self.env.grid_size))\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect(\"equal\")\n",
    "        \n",
    "        ax.set_title(f\"Turn: {frame_data['turn']}\\n\"\n",
    "                    f\"Player A (Health: {frame_data['p1_health']}) | \"\n",
    "                    f\"Player B (Health: {frame_data['p2_health']})\"\n",
    "                    f\"\\nPlayer A Capture Points: {frame_data['p1_points']} | \"\n",
    "                    f\"Player B Capture Points: {frame_data['p2_points']}\")\n",
    "    \n",
    "    def save_animation(self, filename=\"game_replay.gif\", fps=2):\n",
    "        \"\"\"\n",
    "        Save captured frames as animation.\n",
    "        Supports .gif and .mp4 formats.\n",
    "        \"\"\"\n",
    "        if not self.frames:\n",
    "            raise ValueError(\"No frames captured!\")\n",
    "            \n",
    "        fig, ax = plt.subplots(figsize=self.figsize)\n",
    "        \n",
    "        def animate(frame_idx):\n",
    "            self._create_frame(self.frames[frame_idx], ax)\n",
    "            return ax.patches + [ax.title]\n",
    "  \n",
    "        anim = animation.FuncAnimation(\n",
    "            fig, animate, frames=len(self.frames),\n",
    "            interval=1000/fps, blit=True\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            if filename.endswith('.mp4'):\n",
    "                try:\n",
    "                    writer = animation.FFMpegWriter(fps=fps)\n",
    "                    anim.save(filename, writer=writer)\n",
    "                except (FileNotFoundError, RuntimeError):\n",
    "                    print(\"FFmpeg not found. Saving as GIF instead...\")\n",
    "                    filename = filename.replace('.mp4', '.gif')\n",
    "                    anim.save(filename, writer='pillow', fps=fps)\n",
    "            else:\n",
    "                anim.save(filename, writer='pillow', fps=fps)\n",
    "                \n",
    "            print(f\"Animation saved as: {filename}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error saving animation: {str(e)}\")\n",
    "            \n",
    "        finally:\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewards: [0, 0]\n",
      "\n",
      "Rewards: [0, 0]\n",
      "\n",
      "Rewards: [-1, 0]\n",
      "\n",
      "Rewards: [-1, 5]\n",
      "\n",
      "Rewards: [-1, 0]\n",
      "\n",
      "Rewards: [-1, 0]\n",
      "\n",
      "Rewards: [-1, 5]\n",
      "\n",
      "Rewards: [-1, 0]\n",
      "\n",
      "Rewards: [-1, 0]\n",
      "\n",
      "Rewards: [-1, 0]\n",
      "\n",
      "Rewards: [-1, 0]\n",
      "\n",
      "Rewards: [-1, 0]\n",
      "\n",
      "Rewards: [-1, 5]\n",
      "\n",
      "Rewards: [0, 0]\n",
      "\n",
      "Rewards: [0, 0]\n",
      "\n",
      "Rewards: [0, 0]\n",
      "\n",
      "Rewards: [0, 0]\n",
      "\n",
      "Rewards: [5, -1]\n",
      "\n",
      "Rewards: [0, 0]\n",
      "\n",
      "Rewards: [0, 0]\n",
      "\n",
      "Rewards: [0, 0]\n",
      "\n",
      "Rewards: [0, 0]\n",
      "\n",
      "Rewards: [0, 0]\n",
      "\n",
      "Rewards: [-1, 0]\n",
      "\n",
      "Rewards: [-1, 0]\n",
      "\n",
      "Rewards: [-1, 0]\n",
      "\n",
      "Rewards: [-1, 0]\n",
      "\n",
      "Rewards: [-1, 5]\n",
      "\n",
      "Rewards: [0, -1]\n",
      "\n",
      "Rewards: [0, -1]\n",
      "\n",
      "Animation saved as: game_replay.gif\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    env = CombatArenaEnv()\n",
    "    agent_A = TacticalAgent(name=\"Tactical A\")\n",
    "    agent_B = TacticalAgent(name=\"Random B\")\n",
    "    \n",
    "    # Create visualizer\n",
    "    vis = GameVisualizer(env)\n",
    "    \n",
    "    # Reset environment\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    # Capture initial state\n",
    "    vis.capture_frame()\n",
    "    \n",
    "    while not done:\n",
    "        # Get observations for both agents\n",
    "        obs_A = env.get_observation_for_agent(is_agent_one=True)\n",
    "        obs_B = env.get_observation_for_agent(is_agent_one=False)\n",
    "        \n",
    "        # Get actions from agents\n",
    "        action_A = agent_A.select_action(obs_A)\n",
    "        action_B = agent_B.select_action(obs_B)\n",
    "        \n",
    "        # Step environment\n",
    "        obs1, obs2, rewards, done, info = env.step((action_A, action_B))\n",
    "        \n",
    "        # Capture frame\n",
    "        vis.capture_frame()\n",
    "        print(f\"Rewards: {rewards}\\n\")\n",
    "    \n",
    "    # Save animation\n",
    "    vis.save_animation(\"game_replay.gif\", fps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
